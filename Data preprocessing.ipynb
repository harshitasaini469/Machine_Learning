{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60362f5",
   "metadata": {},
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36408ce4",
   "metadata": {},
   "source": [
    "Data preprocessing is a process of preparing the raw data and making it suitable for a machine learning model. It is the first and crucial step while creating a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89340c8c",
   "metadata": {},
   "source": [
    "***Steps in data preprocessing***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf16807",
   "metadata": {},
   "source": [
    "Step 1 :- Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecdfdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Label\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mpt\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991475d5",
   "metadata": {},
   "source": [
    "step 2 :- importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef74687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab5c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting independent and dependent variables\n",
    "\n",
    "x=data_set.iloc[:,:-1].values\n",
    "y=data_set.iloc[:,3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a202fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ec6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362b6ea",
   "metadata": {},
   "source": [
    "step 3 :- Handling the missing data (Replacing missing data with mean value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27b5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# fitting imputer object to the independent variable x.\n",
    "imputer = imputer.fit(x[:, 1:3])\n",
    "# Replacing missing data with the calculated mean value\n",
    "x[:, 1:3] = imputer.transform(x[:, 1:3])\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1aa64",
   "metadata": {},
   "source": [
    "step 4 :- Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f624adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 44.0 72000.0]\n",
      " [2 27.0 48000.0]\n",
      " [1 30.0 54000.0]\n",
      " [2 38.0 61000.0]\n",
      " [1 40.0 63777.77777777778]\n",
      " [0 35.0 58000.0]\n",
      " [2 38.77777777777778 52000.0]\n",
      " [0 48.0 79000.0]\n",
      " [1 50.0 83000.0]\n",
      " [0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Since machine learning model completely works on mathematics and numbers, \n",
    "# but if our dataset would have a categorical variable, then it may create \n",
    "# trouble while building the model. So it is necessary to encode these categorical \n",
    "# variables into numbers.\n",
    "\n",
    "# For country variable\n",
    "\n",
    "label_encoder_x=LabelEncoder()\n",
    "x[:,0]=label_encoder_x.fit_transform(x[:,0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0266df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01\n",
      "  7.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01\n",
      "  4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.00000000e+01\n",
      "  5.40000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01\n",
      "  6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01\n",
      "  6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01\n",
      "  5.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01\n",
      "  5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01\n",
      "  7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.00000000e+01\n",
      "  8.30000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01\n",
      "  6.70000000e+04]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-11525969f59d>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x=np.array(ct.fit_transform(x),dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "# Dummy encoding using oneHotEncoder\n",
    "ct=ColumnTransformer([('Country',OneHotEncoder(),[0])],remainder='passthrough')\n",
    "x=np.array(ct.fit_transform(x),dtype=np.float)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87d7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# for purchased variable\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc13dc",
   "metadata": {},
   "source": [
    "step 5 :- splitting the data set into training and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c7d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c577f",
   "metadata": {},
   "source": [
    "step 6 :- feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0224952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          2.64575131 -0.77459667  0.26306757  0.12381479]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.25350148  0.46175632]\n",
      " [-1.         -0.37796447  1.29099445 -1.97539832 -1.53093341]\n",
      " [-1.         -0.37796447  1.29099445  0.05261351 -1.11141978]\n",
      " [ 1.         -0.37796447 -0.77459667  1.64058505  1.7202972 ]\n",
      " [-1.         -0.37796447  1.29099445 -0.0813118  -0.16751412]\n",
      " [ 1.         -0.37796447 -0.77459667  0.95182631  0.98614835]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.59788085 -0.48214934]]\n",
      "[[ 0.  0.  0. -1. -1.]\n",
      " [ 0.  0.  0.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "st_x=StandardScaler()\n",
    "x_train=st_x.fit_transform(x_train)\n",
    "\n",
    "x_test=st_x.fit_transform(x_test)\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4866f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab73b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e754b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269071e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
